# Домашнее задание к занятию 4. «Оркестрация группой Docker-контейнеров на примере Docker Compose»

Задание выполнено на VPS под управлением ОС Ubuntu 22.04

## Задача 1

#### Создайте собственный образ любой операционной системы (например, debian-11) с помощью Packer версии 1.7.0.

Задание 1 выполнено на VPS под управлением ОС Ubuntu 22.04.

1. Устанавливаем дистрибутив Packer из официального [репозитория](https://developer.hashicorp.com/packer/tutorials/docker-get-started/get-started-install-cli#precompiled-binaries) согласно [инструкции](https://cloud.yandex.ru/docs/tutorials/infrastructure-management/packer-quickstart):
```
su root
curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -
apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
apt-get update
apt-get upgrade
apt-get install packer
```

2. Добавляем путь к папке, в которой находится исполняемый файл, в переменную:
```
export PATH=$PATH:/root/virtualisation
```

3.  Создаем конфигурационный файл config.pkr.hcl, где прописываем провайдера Yandex Cloud:

```
nano config.pkr.hcl

packer {
  required_plugins {
    yandex = {
      version = ">= 1.1.2"
      source  = "github.com/hashicorp/yandex"
    }
  }
}
```

4. Устанавливаем плагин:
```
packer init /root/virtualisation/config.pkr.hcl
```

5. Получаем информацию, необходимую для подготовки конфигурации образа:
```
yc config list
yc vpc subnet list
```

6. Создаем конфигурацию образа операционной системы Debian 11 прямо из [инструкции](https://cloud.yandex.ru/docs/tutorials/infrastructure-management/packer-quickstart), только удалим из примера установку Nginx, так как данное программное обеспечение нам не потребуется для выполнения данного задания (забегая вперед можно дополнить конфигурационный файл установкой Prometheus и Grafana, но по условиям задания данные действия будем выполнять другими инструментами):
```
nano image.pkr.hcl

source "yandex" "autogenerated_1" {
  image_name          = "debian-11"
  folder_id           = "b1gadttfn3t0cohh2hk2"
  source_image_family = "debian-11"
  ssh_username        = "root"
  token               = "y0_Ag-----------------------------0K1VqSs"
  use_ipv4_nat        = "true"
  subnet_id           = "e9brlhk5rpbo0c1f2tu1"
}

build {
  sources = ["source.yandex.autogenerated_1"]

}
```

Примечание - образ необходимо конфигурировать в формате hcl, так как с формат json больше не поддерживается packer.

7. Собираем образ:
```
 packer build image.pkr.hcl
```
![Alt text](https://github.com/LeonidKhoroshev/virtd-homeworks/blob/main/05-virt-04-docker-compose/docker/docker1.png)

8. Проверяем в консоли и в веб-интерфейсе Yandex Cloud
![Alt text](https://github.com/LeonidKhoroshev/virtd-homeworks/blob/main/05-virt-04-docker-compose/docker/docker3.png)
![Alt text](https://github.com/LeonidKhoroshev/virtd-homeworks/blob/main/05-virt-04-docker-compose/docker/docker2.png)


## Задача 2

Создайте вашу первую виртуальную машину в YandexCloud с помощью Terraform (вместо использования веб-интерфейса YandexCloud).
Используйте Terraform-код в директории ([src/terraform](https://github.com/netology-group/virt-homeworks/tree/virt-11/05-virt-04-docker-compose/src/terraform)).

Выбираем создание виртуальной машины с помощью Terraform:
1. Создаем файл main.tf на основе образа, созданного в рамках выполнения задания 1:
```
terraform {
  required_providers {
    yandex = {
      source = "yandex-cloud/yandex"
    }
  }
}
provider "yandex" {
  token = "y0_AgAAAAAp7--------------------PQxQr0K1VqSs"
  cloud_id  = "b1g3ks25rm2qagep03qb"
  folder_id = "b1gadttfn3t0cohh2hk2"
}
resource "yandex_compute_instance" "test" {
  name                      = "test"
  zone                      = "ru-central1-b"
  hostname                  = "test.netology.cloud"
  allow_stopping_for_update = true
  resources {
    cores  = 2
    memory = 2
  }
  boot_disk {
    initialize_params {
      image_id    = "fd8fhfgeggglpdcbsade"
      name        = "test"
      type        = "network-nvme"
      size        = "15"
    }
  }
  network_interface {
    subnet_id = "e2laj8khjjcf3lfs0l3p"
    nat       = true
  }
  metadata = {
    user-data = "${file("/root/terraform/meta.yml")}"
  }
  scheduling_policy {
    preemptible = true
  }
}
```
Здесь по сравнению с примером из лекции внесен ряд изменений, в разделе metadata вместо ssh ключа добавлен параметр user-data со ссылкой на файл meta.yml, в котором создан пользователь и указан ssh ключ для подключения, а также добавлен блок scheduling_polic, который позволяет сделать конфигурируемую машину прерываемой, чтЯндлеко по тарификации YandexCloud на 50% дешевле.

2. Cоздаем файл meta.yml:
```
terra#cloud-config
users:
  - name: leo
    groups: sudo
    shell: /bin/bash
    sudo: 'ALL=(ALL) NOPASSWD:ALL'
    ssh-authorized-keys:
      - ssh-rsa B3NzaC1yc2EA--------nqVgpcANVz root@localhost.localdomain
```

3. Проверяем конфигурацию:
```
terraform validate
```

4. Создаем виртуальную машину на базе ОС Debian 11:
```
terraform apply
```
![Alt text](https://github.com/LeonidKhoroshev/virtd-homeworks/blob/main/05-virt-04-docker-compose/docker/docker4.png)


## Задача 3

С помощью Ansible и Docker Compose разверните на виртуальной машине из предыдущего задания систему мониторинга на основе Prometheus/Grafana.
Используйте Ansible-код в директории ([src/ansible](https://github.com/netology-group/virt-homeworks/tree/virt-11/05-virt-04-docker-compose/src/ansible)).

1. Создаем файл inventory для возможности удаленной настройки программного обеспечения:
```
nano /etc/ansible/inventory

[nodes:children]
manager

[manager]
test.netology.cloud ansible_host=158.160.76.57
```
Проверяем:
```
ansible all --list-hosts
hosts (1):
   test.netology.cloud
```
Пробное подключение:
```
ansible all -m ping -u leo
test.netology.cloud | SUCCESS => {
    "changed": false,
```

2. Проверяем корректность конфигурации Ansible:
```
cat /etc/ansible/ansible.cfg

[defaults]
inventory=./inventory
deprecation_warnings=False
command_warnings=False
ansible_port=22
interpreter_python=/usr/bin/python3
host_key_checking=False
```

3. Составляем  provision.yml (аналогично представленному в материалах, но с учетом изменений, необходимых для работы с Debian):
```
nano provision.yml

- hosts: nodes
  become: yes
  become_user: root
  remote_user: leo

  tasks:
    - name: Create directory for ssh-keys
      file: state=directory mode=0700 dest=/root/.ssh/

    - name: Adding rsa-key in /root/.ssh/authorized_keys
      copy: src=~/.ssh/id_rsa.pub dest=/root/.ssh/authorized_keys owner=root mode=0600
      ignore_errors: yes

    - name: Checking DNS
      command: host -t A google.com

    - name: Installing tools
      apt:
        name={{ item }}
        update_cache=yes
        state=present
      with_items:
        - git
        - curl
        - ca-certificates
        - gnupg

    - name: Add gpg-keys
      command: sudo install -m 0755 -d /etc/apt/keyrings
      command: curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
      command: sudo chmod a+r /etc/apt/keyrings/docker.gpg

    - name: Add the repository to Apt sources
      command: echo "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian bullseye oldstable" /
      | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
      command: sudo apt update

    - name: Installing docker package
      apt:
        name={{ item }}
        state=present
        update_cache=yes
      with_items:
        - docker-ce-cli
        - containerd.io
        - docker-ce
        - docker-buildx-plugin
        - docker-compose-plugin

    - name: Enable docker daemon
      systemd:
        name: docker
        state: started
        enabled: yes

    - name: Write docker-compose files
      become: yes
      copy:
        src: /root/virtualisation/docker-compose.yml
        dest: /home/leo/docker-compose.yml

    - name: Pull all images in compose
      command: docker-compose -f /home/leo/docker-compose.yml pull

    - name: Up all services in compose
      command: docker-compose -f /home/leo/docker-compose.yml up -d
```

4. Копируем к себе в папку docker-compose.yml с контейнерами, планируемыми к запуску на виртуальной машине в YandexCloud (при запуске файла из лекции 3 из 5 контейнеров были перманентно в режиме restarting, поэтому файл немного [доработан](https://github.com/Einsteinish/Docker-Compose-Prometheus-and-Grafana):

```
nano docker-compose.yml

version: '2.1'

networks:
  monitor-net:
    driver: bridge

volumes:
    prometheus_data: {}
    grafana_data: {}

services:

  prometheus:
    image: prom/prometheus:v2.17.1
    container_name: prometheus
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    expose:
      - 9090
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

  alertmanager:
    image: prom/alertmanager:v0.20.0
    container_name: alertmanager
    volumes:
      - ./alertmanager:/etc/alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    restart: unless-stopped
    expose:
      - 9093
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

  nodeexporter:
    image: prom/node-exporter:v0.18.1
    container_name: nodeexporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped
    expose:
      - 9100
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

  cadvisor:
    image: gcr.io/google-containers/cadvisor:v0.34.0
    container_name: cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
      #- /cgroup:/cgroup:ro #doesn't work on MacOS only for Linux
    restart: unless-stopped
    expose:
      - 8080
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

  grafana:
    image: grafana/grafana:6.7.2
    container_name: grafana
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_USER=${ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    restart: unless-stopped
    expose:
      - 3000
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

  pushgateway:
    image: prom/pushgateway:v1.2.0
    container_name: pushgateway
    restart: unless-stopped
    expose:
      - 9091
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"

  caddy:
    image: stefanprodan/caddy
    container_name: caddy
    ports:
      - "3000:3000"
      - "9090:9090"
      - "9093:9093"
      - "9091:9091"
    volumes:
      - ./caddy:/etc/caddy
    environment:
      - ADMIN_USER=${ADMIN_USER}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD}
    restart: unless-stopped
    networks:
      - monitor-net
    labels:
      org.label-schema.group: "monitoring"
```

5. Запускаем наш плейбук:
```
ansible-playbook provision.yml
```
![Alt text](https://github.com/LeonidKhoroshev/virtd-homeworks/blob/main/05-virt-04-docker-compose/docker/docker5.png)

6. Проверяем работу контейнеров:
![Alt text](https://github.com/LeonidKhoroshev/virtd-homeworks/blob/main/05-virt-04-docker-compose/docker/docker6.png)




## Задача 4

1. Откройте веб-браузер, зайдите на страницу http://<внешний_ip_адрес_вашей_ВМ>:3000.
2. Используйте для авторизации логин и пароль из [.env-file](https://github.com/netology-group/virt-homeworks/blob/virt-11/05-virt-04-docker-compose/src/ansible/stack/.env).
3. Изучите доступный интерфейс, найдите в интерфейсе автоматически созданные docker-compose-панели с графиками([dashboards](https://grafana.com/docs/grafana/latest/dashboards/use-dashboards/)).
4. Подождите 5-10 минут, чтобы система мониторинга успела накопить данные.

Переходим по адресу http://158.160.76.57:3000, заходим вод логином и паролем admin:
![Alt text](https://github.com/LeonidKhoroshev/virtd-homeworks/blob/main/05-virt-04-docker-compose/docker/docker7.png)

## Задача 5 (*)

Создайте вторую ВМ и подключите её к мониторингу, развёрнутому на первом сервере.

Чтобы получить зачёт, предоставьте:

- скриншот из Grafana, на котором будут отображаться метрики добавленного вами сервера.


